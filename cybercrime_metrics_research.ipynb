{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5839b51-de3e-4d75-8edc-05560c829e6f",
   "metadata": {},
   "source": [
    "# Note on packages\n",
    "\n",
    "alembic is for migrations\n",
    "ipykernel is for using sqlalchemy easier with Jupyter (not sure if/why needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8a572-4a95-4dad-aef8-e699ca62b9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!poetry add sqlalchemy ipykernel alembic bibtexparser pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a79bc2-8115-4b1c-90bb-d92d662fb93b",
   "metadata": {},
   "source": [
    "# Create db and all missing tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e571d5-e91b-40a2-a3be-e3580db2e89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database created at: cybercrime_analysis.db\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the root and models directories to the Python path\n",
    "sys.path.append(str(Path('.').resolve()))\n",
    "sys.path.append(str((Path('.') / 'models').resolve()))\n",
    "\n",
    "# Now you can import\n",
    "from models.db_models import Base\n",
    "from config import NotebookConfig\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Create the database\n",
    "engine = create_engine(f\"sqlite:///{NotebookConfig.DB_FILE}\")\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "print(f\"✅ Database created at: {NotebookConfig.DB_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a4914b-5fa9-4b6d-9de1-756b6483af93",
   "metadata": {},
   "source": [
    "# Import papers (sources) that Umind found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42351639-ffb5-4cd3-bc52-7ab2248a94fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import csv\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration section.\n",
    "TOPIC_NAME = \"Cybercrime and intervention metrics\"\n",
    "\n",
    "# Add the root and models directories to the Python path.\n",
    "sys.path.append(str(Path('.').resolve()))\n",
    "sys.path.append(str((Path('.') / 'models').resolve()))\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "from config import NotebookConfig\n",
    "from db_models import Source, generate_cite_key, UnmindSourceRelevanceRating  # Import from models\n",
    "\n",
    "def unmind_import():\n",
    "    csv_path = NotebookConfig.INPUT_DIR / \"undermind-cybercrime-table-export.csv\"\n",
    "    if not csv_path.exists():\n",
    "        print(f\"CSV file not found: {csv_path}\")\n",
    "        return\n",
    "\n",
    "    engine = create_engine(f\"sqlite:///{NotebookConfig.DB_FILE}\")\n",
    "    Session = sessionmaker(bind=engine)\n",
    "    session = Session()\n",
    "\n",
    "    sources_to_add = []\n",
    "    ratings_to_add = []\n",
    "\n",
    "    with open(csv_path, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            # Get CSV fields; adjust keys if necessary.\n",
    "            title = row.get(\"Title\", \"\").strip()\n",
    "            authors = row.get(\"Authors\", \"\").strip()\n",
    "            try:\n",
    "                year = int(row.get(\"Year\", \"\").strip())\n",
    "            except (ValueError, AttributeError):\n",
    "                year = None\n",
    "\n",
    "            date_str = row.get(\"Date\", \"\").strip()\n",
    "            date_obj = None\n",
    "            if date_str:\n",
    "                try:\n",
    "                    # Adjust the date format to match \"04/04/2018\".\n",
    "                    date_obj = datetime.strptime(date_str, \"%m/%d/%Y\").date()\n",
    "                except ValueError:\n",
    "                    date_obj = None\n",
    "\n",
    "            abstract = row.get(\"Abstract\", \"\").strip()\n",
    "            journal = row.get(\"Journal\", \"\").strip()\n",
    "            try:\n",
    "                citation_count = int(row.get(\"Citation Count\", \"\").strip())\n",
    "            except (ValueError, AttributeError):\n",
    "                citation_count = None\n",
    "            try:\n",
    "                citation_velocity = float(row.get(\"Citation Velocity\", \"\").strip())\n",
    "            except (ValueError, AttributeError):\n",
    "                citation_velocity = None\n",
    "            doi = row.get(\"DOI\", \"\").strip()\n",
    "            link = row.get(\"Link\", \"\").strip()\n",
    "            external_ids = row.get(\"External IDs\", \"\").strip()\n",
    "            is_open_access = row.get(\"Is Open Access\", \"\").strip().lower() in [\"true\", \"1\", \"yes\"]\n",
    "            open_access_link = row.get(\"Open Access Link\", \"\").strip()\n",
    "            semantic_scholar_id = row.get(\"Semantic Scholar ID\", \"\").strip()\n",
    "\n",
    "            # Generate the citation key using the generate_cite_key function.\n",
    "            cite_key = generate_cite_key(authors, year, title)\n",
    "\n",
    "            # Create the Source instance.\n",
    "            source = Source(\n",
    "                cite_key=cite_key,\n",
    "                title=title,\n",
    "                year=year,\n",
    "                date=date_obj,\n",
    "                authors=authors,\n",
    "                abstract=abstract,\n",
    "                journal=journal,\n",
    "                citation_count=citation_count,\n",
    "                citation_velocity=citation_velocity,\n",
    "                doi=doi,\n",
    "                link=link,\n",
    "                external_ids=external_ids,\n",
    "                is_open_access=is_open_access,\n",
    "                open_access_link=open_access_link,\n",
    "                semantic_scholar_id=semantic_scholar_id\n",
    "            )\n",
    "            sources_to_add.append(source)\n",
    "\n",
    "            # Get the rating from the CSV (\"Topic Match Score\").\n",
    "            try:\n",
    "                topic_match_score = float(row.get(\"Topic Match Score\", \"\").strip())\n",
    "            except (ValueError, AttributeError):\n",
    "                topic_match_score = 0.0\n",
    "\n",
    "            # Create the UnmindSourceRelevanceRating instance.\n",
    "            rating = UnmindSourceRelevanceRating(\n",
    "                cite_key=cite_key,\n",
    "                rating=topic_match_score,\n",
    "                topic=TOPIC_NAME\n",
    "            )\n",
    "            ratings_to_add.append(rating)\n",
    "\n",
    "    # Bulk insert the sources and ratings.\n",
    "    session.bulk_save_objects(sources_to_add)\n",
    "    session.bulk_save_objects(ratings_to_add)\n",
    "    session.commit()\n",
    "    print(f\"Imported {len(sources_to_add)} sources and {len(ratings_to_add)} ratings successfully.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unmind_import()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290c12d2-f43f-4052-ac6b-174e066994e0",
   "metadata": {},
   "source": [
    "# Helper cell to clear Source table of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c9de73-0edb-4c7c-98d0-36bb70375136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Add the root and models directories to the Python path.\n",
    "sys.path.append(str(Path('.').resolve()))\n",
    "sys.path.append(str((Path('.') / 'models').resolve()))\n",
    "\n",
    "from config import NotebookConfig\n",
    "from db_models import Source  # assuming your Source model is defined in models/db_models.py\n",
    "\n",
    "# Create the engine and session.\n",
    "engine = create_engine(f\"sqlite:///{NotebookConfig.DB_FILE}\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Delete all rows from the Source table.\n",
    "deleted_rows = session.query(Source).delete()\n",
    "session.commit()\n",
    "\n",
    "print(f\"Deleted {deleted_rows} rows from the Source table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab57baad-6676-4d7c-9d5e-e8bcdcdb63e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "# Add the root and models directories to the Python path.\n",
    "sys.path.append(str(Path('.').resolve()))\n",
    "sys.path.append(str((Path('.') / 'models').resolve()))\n",
    "\n",
    "from config import NotebookConfig\n",
    "from db_models import Source\n",
    "\n",
    "# Create the database engine and session.\n",
    "engine = create_engine(f\"sqlite:///{NotebookConfig.DB_FILE}\")\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Query the database for all cite keys.\n",
    "sources = session.query(Source.cite_key).all()\n",
    "\n",
    "# Extract the cite keys from the query result.\n",
    "cite_keys = [key for (key,) in sources]\n",
    "\n",
    "# Print out the list of cite keys.\n",
    "print(\"Cite Keys:\")\n",
    "for key in cite_keys:\n",
    "    print(key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eabe9d3-7ca2-4125-b1ae-61904e9f301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new Sources even where I don't have full details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a283b6e8-ef8f-45b3-a8bc-208c28165803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from models.db_models import Source, engine\n",
    "from config import NotebookConfig\n",
    "\n",
    "# Create a new SQLAlchemy session.\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Define the path to the JSON file.\n",
    "json_file_path = NotebookConfig.INPUT_DIR / \"new_papers.txt\"\n",
    "\n",
    "# Load the JSON content from the file.\n",
    "with open(json_file_path, 'r') as file:\n",
    "    papers_data = json.load(file)\n",
    "\n",
    "# Iterate over each paper in the JSON.\n",
    "for paper in papers_data:\n",
    "    # Check if a source with the same cite_key already exists.\n",
    "    existing_source = session.query(Source).filter_by(cite_key=paper[\"cite_key\"]).first()\n",
    "    if existing_source:\n",
    "        print(f\"Source with cite_key '{paper['cite_key']}' already exists. Skipping insertion.\")\n",
    "    else:\n",
    "        # Create a new Source object using the data from the JSON.\n",
    "        new_source = Source(\n",
    "            cite_key=paper.get(\"cite_key\"),\n",
    "            title=paper.get(\"title\"),\n",
    "            authors=paper.get(\"authors\"),\n",
    "            year=paper.get(\"year\")\n",
    "        )\n",
    "        session.add(new_source)\n",
    "        print(f\"Added new source: {paper['cite_key']}\")\n",
    "\n",
    "# Commit the session to save all changes to the database.\n",
    "session.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0811f8ac-f445-475f-a746-c63f90a80aaf",
   "metadata": {},
   "source": [
    "# Add Research Notes to the db\n",
    "\n",
    "The json schema for notes this uses is the following (note that the chicago_citation is not used but is useful to have a visual check for the user.)\n",
    "\n",
    "[\n",
    "  {\n",
    "    \"cite_key\": \"anderson_2012_mtco\",\n",
    "    \"chicago_citation\": \"Anderson, Ross J., et al. 2012. \\\"Measuring the Cost of Cybercrime.\\\"\",\n",
    "    \"reports\": [\n",
    "      {\n",
    "        \"deep_research_report\": \"2025_04_03_undermind_cybercrime_and_intervention_metrics\",\n",
    "        \"research_note\": \"This paper is referenced as part of the early foundational work (2012-2015) in cybercrime metrics, specifically pioneering systematic studies on the economic costs of cybercrime. It established frameworks to measure financial impacts and highlighted gaps in reliable data for policymaking.\"\n",
    "      }\n",
    "    ]\n",
    "  },"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e73c13-ff8f-44f7-806c-9c379dc66487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from models.db_models import Source, DeepResearchReport, ResearchNote, engine, NoteRouteType\n",
    "from config import NotebookConfig\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIGURATION: Set the route for the research notes.\n",
    "# Options: \"deep_research_report\", \"note_taking\", \"ai_notes\"\n",
    "ROUTE = \"deep_research_report\"  # Change this value as needed.\n",
    "# -----------------------------\n",
    "\n",
    "# Convert the route to the appropriate enum value.\n",
    "try:\n",
    "    note_route = NoteRouteType(ROUTE)\n",
    "except ValueError:\n",
    "    raise ValueError(\"Invalid route. Valid options are: deep_research_report, note_taking, ai_notes.\")\n",
    "\n",
    "# Create a new SQLAlchemy session.\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Define the path to the JSON file.\n",
    "json_file_path = NotebookConfig.INPUT_DIR / \"notes_on_sources_1.txt\"\n",
    "\n",
    "# Load the JSON content from the file.\n",
    "with open(json_file_path, 'r') as file:\n",
    "    notes_data = json.load(file)\n",
    "\n",
    "# Process each note entry in the JSON.\n",
    "for note_entry in notes_data:\n",
    "    cite_key = note_entry.get(\"cite_key\")\n",
    "    # Ensure the cite_key exists in the Source table.\n",
    "    source = session.query(Source).filter_by(cite_key=cite_key).first()\n",
    "    if not source:\n",
    "        print(f\"Source with cite_key '{cite_key}' not found. Skipping its notes.\")\n",
    "        continue\n",
    "    \n",
    "    # Process each report under the note entry.\n",
    "    for report in note_entry.get(\"reports\", []):\n",
    "        report_name = report.get(\"deep_research_report\")\n",
    "        research_note_text = report.get(\"research_note\")\n",
    "        \n",
    "        if not report_name or not research_note_text:\n",
    "            print(f\"Missing deep_research_report or research_note for cite_key '{cite_key}'. Skipping this report.\")\n",
    "            continue\n",
    "        \n",
    "        # Check if the deep research report already exists.\n",
    "        deep_report = session.query(DeepResearchReport).filter_by(name=report_name).first()\n",
    "        if not deep_report:\n",
    "            deep_report = DeepResearchReport(name=report_name)\n",
    "            session.add(deep_report)\n",
    "            session.commit()  # Commit early so deep_report gets an ID.\n",
    "            print(f\"Added new DeepResearchReport: {report_name}\")\n",
    "        \n",
    "        # Check if the note already exists based on cite_key and note_text.\n",
    "        existing_note = session.query(ResearchNote).filter_by(cite_key=cite_key, note_text=research_note_text).first()\n",
    "        if existing_note:\n",
    "            print(f\"Note for cite_key '{cite_key}' with the same text already exists. Skipping this note.\")\n",
    "            continue\n",
    "\n",
    "        # Create a new ResearchNote for this report and set the cite_key.\n",
    "        new_note = ResearchNote(\n",
    "            note_text=research_note_text,\n",
    "            route=note_route,\n",
    "            deep_research_report=deep_report,\n",
    "            cite_key=cite_key  # Associate note with the source's cite_key.\n",
    "        )\n",
    "        session.add(new_note)\n",
    "        print(f\"Added note for cite_key '{cite_key}' under report '{report_name}'.\")\n",
    "\n",
    "# Commit all changes.\n",
    "session.commit()\n",
    "print(\"Finished processing notes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1999227-4429-4736-8e84-e0c63057663f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import bibtexparser\n",
    "from bibtexparser.bparser import BibTexParser\n",
    "from bibtexparser.customization import homogenize_latex_encoding\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from models.db_models import Source, engine\n",
    "from config import NotebookConfig\n",
    "\n",
    "def remove_extra_braces(s):\n",
    "    \"\"\"Remove all curly braces from a string.\"\"\"\n",
    "    return s.replace(\"{\", \"\").replace(\"}\", \"\")\n",
    "\n",
    "def convert_bib_cite_key(bib_key, title):\n",
    "    \"\"\"\n",
    "    Convert a BibTeX cite key to the custom format:\n",
    "      - Lowercase the letters before the first digit.\n",
    "      - Insert an underscore.\n",
    "      - Keep only the first four digits.\n",
    "      - Add an underscore and then the lowercase of the first letters of the first four words in the title.\n",
    "    \"\"\"\n",
    "    # Remove extraneous braces from the title before processing.\n",
    "    clean_title = remove_extra_braces(title)\n",
    "    \n",
    "    # Lowercase the letters before the first digit.\n",
    "    prefix_match = re.match(r'^([A-Za-z]+)', bib_key)\n",
    "    prefix = prefix_match.group(1).lower() if prefix_match else ''\n",
    "    \n",
    "    # Extract the first four digits.\n",
    "    digits_match = re.search(r'(\\d{4})', bib_key)\n",
    "    digits = digits_match.group(1) if digits_match else ''\n",
    "    \n",
    "    # Get the first letters of the first four words of the cleaned title.\n",
    "    words = re.findall(r'\\w+', clean_title)\n",
    "    letters = ''.join(word[0].lower() for word in words[:4])\n",
    "    \n",
    "    return f\"{prefix}_{digits}_{letters}\"\n",
    "\n",
    "# Create a new SQLAlchemy session.\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Define the path to your papers.bib file.\n",
    "bib_file_path = NotebookConfig.INPUT_DIR / \"papers.bib\"\n",
    "\n",
    "with open(bib_file_path, 'r') as bibtex_file:\n",
    "    bibtex_str = bibtex_file.read()\n",
    "\n",
    "# Parse the BibTeX file.\n",
    "parser = BibTexParser(common_strings=True)\n",
    "parser.customization = homogenize_latex_encoding\n",
    "bib_database = bibtexparser.loads(bibtex_str, parser=parser)\n",
    "\n",
    "for entry in bib_database.entries:\n",
    "    original_key = entry.get('ID')  # the original BibTeX key\n",
    "    raw_title = entry.get('title', '')\n",
    "    # Remove extra braces from the title before saving.\n",
    "    title = remove_extra_braces(raw_title)\n",
    "    \n",
    "    new_cite_key = convert_bib_cite_key(original_key, title)\n",
    "    \n",
    "    # Extract other fields from the BibTeX entry.\n",
    "    url = entry.get('url')\n",
    "    journal = entry.get('journal')\n",
    "    booktitle = entry.get('booktitle')\n",
    "    pages = entry.get('pages')\n",
    "    volume = entry.get('volume')\n",
    "    year = int(entry.get('year')) if entry.get('year') and entry.get('year').isdigit() else None\n",
    "    authors = entry.get('author')\n",
    "    \n",
    "    # Check if a Source with the new cite key exists.\n",
    "    source = session.query(Source).filter_by(cite_key=new_cite_key).first()\n",
    "    \n",
    "    if source:\n",
    "        # Update the link field unconditionally.\n",
    "        source.link = url\n",
    "        # Update journal, volume, booktitle, pages if they are not already set (ignoring values like \"unknown\").\n",
    "        if not source.journal and journal and journal.lower() != \"unknown\":\n",
    "            source.journal = journal\n",
    "        if not source.volume:\n",
    "            source.volume = volume\n",
    "        if not source.booktitle and booktitle and booktitle.lower() != \"unknown\":\n",
    "            source.booktitle = booktitle\n",
    "        if not source.pages:\n",
    "            source.pages = pages\n",
    "        print(f\"Updated Source with cite_key {new_cite_key}\")\n",
    "    else:\n",
    "        # Create a new Source with the provided fields.\n",
    "        new_source = Source(\n",
    "            cite_key=new_cite_key,\n",
    "            title=title,\n",
    "            authors=authors,\n",
    "            year=year,\n",
    "            link=url,\n",
    "            journal=journal if journal and journal.lower() != \"unknown\" else None,\n",
    "            booktitle=booktitle if booktitle and booktitle.lower() != \"unknown\" else None,\n",
    "            pages=pages,\n",
    "            volume=volume\n",
    "        )\n",
    "        session.add(new_source)\n",
    "        print(f\"Added new Source with cite_key {new_cite_key}\")\n",
    "\n",
    "# Commit the changes to the database.\n",
    "session.commit()\n",
    "print(\"Finished processing papers.bib\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617ed869-ed18-41d8-9638-acf601f74a82",
   "metadata": {},
   "source": [
    "# Helper Cell: Pretty Print a JSON and show in a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b5fc38-1ea0-494c-a5ea-81e4f7a7f189",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import JSON, display\n",
    "\n",
    "# Paste your JSON data as a Python list (or load it from a file).\n",
    "data = [\n",
    "{\n",
    "\"impact_id\": 1,\n",
    "\"impact_text\": \"DETECTED - Cybercrime and transnational threats impacting the UK are DETECTED and notified to UK authorities.\",\n",
    "\"indicators\": [\n",
    "{\n",
    "\"indicator_id\": \"1.1\",\n",
    "\"indicator_text\": \"Volume, quality, and timeliness of actionable intelligence packages on UK-relevant threats/actors shared by partner country agencies with UK authorities (NCA, NCSC, Police).\",\n",
    "\"potential_sources\": [\n",
    "\"UK Law Enforcement/NCSC internal reporting systems.\",\n",
    "\"Programme M&E records.\",\n",
    "\"Reports from international bodies (Interpol, Europol).\"\n",
    "],\n",
    "\"relevant_insights\": [\n",
    "{\n",
    "\"insight_text\": \"Literature emphasizes international cooperation frameworks (e.g., Budapest Convention) as crucial structures enabling effective intelligence sharing (hussain_2023_acao, ugwu_2024_atet). Assessing adherence to or use of such frameworks can be a proxy for cooperation maturity.\",\n",
    "\"cite_keys\": [\n",
    "\"hussain_2023_acao\",\n",
    "\"ugwu_2024_atet\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"While essential (shevko_2024_ccsa, anishchuk_2024_tpoc), the provided literature offers limited specific metrics for measuring the quality and actionability of shared intelligence itself; this often relies on recipient agency assessment.\",\n",
    "\"cite_keys\": [\n",
    "\"shevko_2024_ccsa\",\n",
    "\"anishchuk_2024_tpoc\"\n",
    "]\n",
    "}\n",
    "],\n",
    "\"follow_up_source_reading_questions\": [\n",
    "\"How did hussain_2023_acao or ugwu_2024_atet describe the mechanisms or impact of the Budapest Convention in practice?\",\n",
    "\"Did shevko_2024_ccsa or anishchuk_2024_tpoc discuss specific mechanisms or best practices for effective international information sharing beyond stating its necessity?\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"indicator_id\": \"1.2\",\n",
    "\"indicator_text\": \"Number of successful UK-relevant cybercrime detections (e.g., specific campaigns, actors, victim reports) originating from investigations or monitoring within partner countries enabled by programme support.\",\n",
    "\"potential_sources\": [\n",
    "\"Programme M&E records documenting specific detections linked to capabilities.\",\n",
    "\"Case files from UK/Partner joint operations.\",\n",
    "\"Partner country agency reports (if shared).\"\n",
    "],\n",
    "\"relevant_insights\": [\n",
    "{\n",
    "\"insight_text\": \"Researchers use technical measures like analysis of IDPS alert characteristics (miani_2015_apeo) or honeypot detection rates (rowe_2006_mteo) as indicators of detection activity within specific systems.\",\n",
    "\"cite_keys\": [\n",
    "\"miani_2015_apeo\",\n",
    "\"rowe_2006_mteo\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"Studies suggest modernised legal frameworks are correlated with higher enforcement success/detection leading to prosecution (na_2024_elrt), indicating enabling legal environment is a key factor for this outcome.\",\n",
    "\"cite_keys\": [\n",
    "\"na_2024_elrt\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"Attributing detections specifically to programme support requires robust M&E tracking inputs (e.g., training, tools) to specific detection outputs/cases.\",\n",
    "\"cite_keys\": []\n",
    "}\n",
    "],\n",
    "\"follow_up_source_reading_questions\": [\n",
    "\"What specific IDPS alert characteristics did miani_2015_apeo find useful as security incident indicators?\",\n",
    "\"How did na_2024_elrt measure or evidence the 45% increase in prosecution rates attributed to modern laws?\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"indicator_id\": \"1.3\",\n",
    "\"indicator_text\": \"Increased reporting by partner country citizens/businesses of UK-relevant cybercrime through established (potentially programme-supported) channels.\",\n",
    "\"potential_sources\": [\n",
    "\"Data from partner country reporting mechanisms (if accessible & filterable).\",\n",
    "\"Programme M&E assessing usage of supported channels.\"\n",
    "],\n",
    "\"relevant_insights\": [\n",
    "{\n",
    "\"insight_text\": \"Research demonstrates reporting interface effectiveness can be improved and measured through factors like usability, user trust, and perceived crime severity, based on user testing and surveys (bidgoli_2019_rnre, Undermind [17]).\",\n",
    "\"cite_keys\": [\n",
    "\"bidgoli_2019_rnre\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"Although victim surveys (bergh_2018_voci, breen_2022_alsm) provide prevalence estimates, the literature highlights underreporting and standardization issues (chen_2023_etgg, woods_2022_reoc) limiting their use for direct comparison or tracking programme impact on reporting behaviour itself, unless the programme directly improves survey mechanisms.\",\n",
    "\"cite_keys\": [\n",
    "\"bergh_2018_voci\",\n",
    "\"breen_2022_alsm\",\n",
    "\"chen_2023_etgg\",\n",
    "\"woods_2022_reoc\"\n",
    "]\n",
    "}\n",
    "],\n",
    "\"follow_up_source_reading_questions\": [\n",
    "\"What specific design elements or usability metrics did bidgoli_2019_rnre test or find effective for their reporting interface?\",\n",
    "\"Did bergh_2018_voci discuss specific reasons for underreporting identified through their review of European victim surveys?\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"indicator_id\": \"1.4\",\n",
    "\"indicator_text\": \"Increased identification and reporting by partner countries of malicious infrastructure (e.g., C2 servers, phishing sites) hosted within their jurisdiction that targets UK victims/interests.\",\n",
    "\"potential_sources\": [\n",
    "\"Partner country CERT/ISP/Law Enforcement reports (if shared).\",\n",
    "\"NCSC/NCA data correlating infrastructure locations.\",\n",
    "\"Threat intelligence feeds (public/commercial).\",\n",
    "\"Analysis of honeypot/network traffic data.\"\n",
    "],\n",
    "\"relevant_insights\": [\n",
    "{\n",
    "\"insight_text\": \"Literature demonstrates successful identification using technical sources like honeypot systems (thomas_2017_1dou, rowe_2006_mteo), analysis of backscatter/network traffic (wang_2020_dcpi, meland_2021_asms), and longitudinal analysis of DDoS/attack data (collier_2021_iiar).\",\n",
    "\"cite_keys\": [\n",
    "\"thomas_2017_1dou\",\n",
    "\"rowe_2006_mteo\",\n",
    "\"wang_2020_dcpi\",\n",
    "\"meland_2021_asms\",\n",
    "\"collier_2021_iiar\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"Cross-national datasets classifying malicious URLs/domains hosted globally can be used to track infrastructure prevalence in partner countries (amin_2020_tsao).\",\n",
    "\"cite_keys\": [\n",
    "\"amin_2020_tsao\"\n",
    "]\n",
    "}\n",
    "],\n",
    "\"follow_up_source_reading_questions\": [\n",
    "\"What type of honeypots or data (e.g., UDP reflectors) did thomas_2017_1dou find effective for tracking DDoS infrastructure?\",\n",
    "\"What methodology did amin_2020_tsao use for classifying URLs and identifying high-risk countries in their dataset?\"\n",
    "]\n",
    "}\n",
    "]\n",
    "},\n",
    "{\n",
    "\"impact_id\": 2,\n",
    "\"impact_text\": \"DISRUPTED - Cybercrime and transnational threats impacting UK interests are DISRUPTED.\",\n",
    "\"indicators\": [\n",
    "{\n",
    "\"indicator_id\": \"2.1\",\n",
    "\"indicator_text\": \"Number and scale of cybercriminal operations (actors, infrastructure, markets) impacting the UK that are disrupted or dismantled by partner country authorities (potentially jointly or with UK support/intel derived from capacity building).\",\n",
    "\"potential_sources\": [\n",
    "\"Programme M&E records tracking disruptions.\",\n",
    "\"UK Law Enforcement/NCSC reporting.\",\n",
    "\"Partner agency reports (if shared).\",\n",
    "\"Press releases/official reports.\"\n",
    "],\n",
    "\"relevant_insights\": [\n",
    "{\n",
    "\"insight_text\": \"Research uses longitudinal analysis of attack data (e.g., time series) to measure the impact of disruptions like infrastructure takedowns (collier_2021_iiar).\",\n",
    "\"cite_keys\": [\n",
    "\"collier_2021_iiar\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"Successful disruption relies heavily on international cooperation structures and capable legal frameworks enabling swift action (shevko_2024_ccsa, hussain_2023_acao).\",\n",
    "\"cite_keys\": [\n",
    "\"shevko_2024_ccsa\",\n",
    "\"hussain_2023_acao\"\n",
    "]\n",
    "}\n",
    "],\n",
    "\"follow_up_source_reading_questions\": [\n",
    "\"What specific metrics (e.g., attack volume, type, source) did collier_2021_iiar track in their time-series analysis before/after disruption?\",\n",
    "\"Did shevko_2024_ccsa provide examples of specific cooperative actions that led to successful disruptions?\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"indicator_id\": \"2.2\",\n",
    "\"indicator_text\": \"Number of arrests and successful prosecutions in partner countries of cybercriminals targeting UK victims/interests, resulting from programme-supported capabilities or investigations.\",\n",
    "\"potential_sources\": [\n",
    "\"Programme M&E records linking support to cases.\",\n",
    "\"Partner judicial/police records (if accessible).\",\n",
    "\"UK Law Enforcement liaison reporting.\",\n",
    "\"MLAT request outcomes.\"\n",
    "],\n",
    "\"relevant_insights\": [\n",
    "{\n",
    "\"insight_text\": \"Studies indicate a correlation between modernised cybercrime laws/legal frameworks and increased prosecution rates (na_2024_elrt), making legal capacity a key enabler.\",\n",
    "\"cite_keys\": [\n",
    "\"na_2024_elrt\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"Measuring the programme's specific contribution requires M&E to document how supported capabilities (e.g., digital forensics, legal training) were utilised in successful cases.\",\n",
    "\"cite_keys\": []\n",
    "}\n",
    "],\n",
    "\"follow_up_source_reading_questions\": [\n",
    "\"What was the methodology used by na_2024_elrt to establish the correlation between modern laws and the 45% higher prosecution rate?\",\n",
    "\"Are there specific types of legal provisions highlighted in hussain_2023_acao or na_2024_elrt that are particularly crucial for enabling prosecutions?\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"indicator_id\": \"2.3\",\n",
    "\"indicator_text\": \"Measurable reduction in specific UK-impacting malicious activities (e.g., spam from partner country IPs, specific malware C&C traffic, successful phishing attempts attributed to actors in partner country) following partner country disruption actions.\",\n",
    "\"potential_sources\": [\n",
    "\"NCSC Active Cyber Defence reports/data.\",\n",
    "\"Threat intelligence feeds.\",\n",
    "\"Network traffic analysis (pre/post disruption).\",\n",
    "\"Cybersecurity vendor data.\"\n",
    "],\n",
    "\"relevant_insights\": [\n",
    "{\n",
    "\"insight_text\": \"Researchers successfully use analysis of technical data sources (network traces, logs, honeypots, backscatter) pre- and post-intervention to quantify reductions in malicious activity (meland_2021_asms, wang_2020_dcpi, collier_2021_iiar).\",\n",
    "\"cite_keys\": [\n",
    "\"meland_2021_asms\",\n",
    "\"wang_2020_dcpi\",\n",
    "\"collier_2021_iiar\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"While reduction is measurable, attributing it solely to disruption requires careful analysis, as threat actors adapt tactics (collier_2021_iiar implies this with changing infrastructure). Long-term monitoring is needed.\",\n",
    "\"cite_keys\": [\n",
    "\"collier_2021_iiar\"\n",
    "]\n",
    "}\n",
    "],\n",
    "\"follow_up_source_reading_questions\": [\n",
    "\"What specific data sources (e.g., network vs system data, specific threat feeds) did meland_2021_asms find most useful for measuring activity changes?\",\n",
    "\"Did collier_2021_iiar observe specific ways actors adapted following disruption efforts?\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"indicator_id\": \"2.4\",\n",
    "\"indicator_text\": \"Adoption and implementation by partner countries of specific policies, regulations, or technical standards (promoted through capacity building) aimed at disrupting cybercrime capabilities (e.g., ISP actions against botnets, cryptocurrency regulations).\",\n",
    "\"potential_sources\": [\n",
    "\"Programme M&E tracking policy adoption.\",\n",
    "\"Partner government publications/legislation.\",\n",
    "\"International bodies monitoring policy implementation.\"\n",
    "],\n",
    "\"relevant_insights\": [\n",
    "{\n",
    "\"insight_text\": \"The literature highlights specific legislation (e.g., Pakistan's Prevention of Electronic Act - hussain_2023_acao) and governance frameworks (ugwu_2024_atet) as key countermeasures; tracking adoption of similar measures is a valid indicator.\",\n",
    "\"cite_keys\": [\n",
    "\"hussain_2023_acao\",\n",
    "\"ugwu_2024_atet\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"Policy surveillance methodology, as proposed by dupont_2019_eteo, provides a structured approach for tracking the adoption and features of such policies globally or regionally.\",\n",
    "\"cite_keys\": [\n",
    "\"dupont_2019_eteo\"\n",
    "]\n",
    "}\n",
    "],\n",
    "\"follow_up_source_reading_questions\": [\n",
    "\"Did dupont_2019_eteo suggest specific data points or features to track in a cybercrime policy monitoring framework?\",\n",
    "\"What specific aspects of Pakistan's Act did hussain_2023_acao highlight as being crucial for combating cybercrime?\"\n",
    "]\n",
    "}\n",
    "]\n",
    "},\n",
    "{\n",
    "\"impact_id\": 3,\n",
    "\"impact_text\": \"DETERRED - Cybercriminals and states are DETERRED by higher risks, higher costs or reduced return.\",\n",
    "\"indicators\": [\n",
    "{\n",
    "\"indicator_id\": \"3.1\",\n",
    "\"indicator_text\": \"Evidence of increased operational cost or difficulty for specific UK-targeting threat actors operating from or transiting through partner countries, attributed to enhanced partner capabilities (e.g., forcing changes in TTPs, infrastructure relocation).\",\n",
    "\"potential_sources\": [\n",
    "\"UK/Partner threat intelligence analysis (qualitative).\",\n",
    "\"Academic studies on cybercrime economics/actor adaptation.\",\n",
    "\"Long-term analysis of disruption impacts (Indicator 2.3).\"\n",
    "],\n",
    "\"relevant_insights\": [\n",
    "{\n",
    "\"insight_text\": \"Researchers identify 'attacker cost' (often measured by time or simulated effort) as a key metric for evaluating countermeasure effectiveness, directly relating to deterrence (sandoval_2010_miac, Elicit report).\",\n",
    "\"cite_keys\": [\n",
    "\"sandoval_2010_miac\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"Studies suggest countermeasures are most effective (and likely deterring) when they target the financial 'revenue streams' or business models of attackers (fajar_2020_tist, an_2018_adat). Observing adaptation away from disrupted revenue models indicates success.\",\n",
    "\"cite_keys\": [\n",
    "\"fajar_2020_tist\",\n",
    "\"an_2018_adat\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"Measuring increased cost often relies on qualitative intelligence observing changes in actor behaviour/TTPs, rather than direct financial data from criminals.\",\n",
    "\"cite_keys\": []\n",
    "}\n",
    "],\n",
    "\"follow_up_source_reading_questions\": [\n",
    "\"How did sandoval_2010_miac operationalize or simulate 'attacker cost' in their study?\",\n",
    "\"What methods did fajar_2020_tist or an_2018_adat use to analyze the economic impact on attacker revenue streams?\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"indicator_id\": \"3.2\",\n",
    "\"indicator_text\": \"Increased number of partner country-led actions (e.g., policy statements, joint attributions, diplomatic actions, operational disruptions) against state or state-sponsored actors whose activities impact the UK.\",\n",
    "\"potential_sources\": [\n",
    "\"Programme M&E tracking partner actions.\",\n",
    "\"Public statements from partner governments.\",\n",
    "\"Reporting on international diplomatic engagements.\",\n",
    "\"Joint attribution statements.\"\n",
    "],\n",
    "\"relevant_insights\": [\n",
    "{\n",
    "\"insight_text\": \"While direct measurement of state actor deterrence is absent in the provided literature, tracking coordinated international actions (advocated by shevko_2024_ccsa, ugwu_2024_atet, anishchuk_2024_tpoc) serves as an output indicator for collective signalling intended to deter.\",\n",
    "\"cite_keys\": [\n",
    "\"shevko_2024_ccsa\",\n",
    "\"ugwu_2024_atet\",\n",
    "\"anishchuk_2024_tpoc\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"State & Transnational Threats are part of the Theory of Change (Node 17, 18, 19); measuring partner actions in this space is feasible, measuring the deterrent effect is the challenge.\",\n",
    "\"cite_keys\": []\n",
    "}\n",
    "],\n",
    "\"follow_up_source_reading_questions\": [\n",
    "\"Did the cooperation papers (shevko_2024_ccsa, ugwu_2024_atet, anishchuk_2024_tpoc) give examples of specific types of successful joint actions taken against state-level threats?\",\n",
    "]\n",
    "},\n",
    "{\n",
    "\"indicator_id\": \"3.3\",\n",
    "\"indicator_text\": \"Demonstrable shift by partner countries towards proactive cybercrime prevention and improved cybersecurity posture (e.g., adoption of frameworks, public awareness campaigns, CERT maturity) resulting from capacity building.\",\n",
    "\"potential_sources\": [\n",
    "\"Programme M&E tracking capabilities/framework adoption.\",\n",
    "\"National cybersecurity assessments/indices.\",\n",
    "\"Partner national cybersecurity strategy documents/reports.\",\n",
    "\"Regional body reports.\"\n",
    "],\n",
    "\"relevant_insights\": [\n",
    "{\n",
    "\"insight_text\": \"Researchers identify the implementation of cybersecurity frameworks and protocols as an effective countermeasure (cassidy_2024_etac, saeed_2021_catp) which contributes to a stronger defensive posture, increasing baseline difficulty for attackers.\",\n",
    "\"cite_keys\": [\n",
    "\"cassidy_2024_etac\",\n",
    "\"saeed_2021_catp\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"Frameworks like the GQIM model (albluwi_2017_fpec) or maturity models (lippmann_2012_csmp) offer structured ways, used in research/practice, to assess and improve security posture over time.\",\n",
    "\"cite_keys\": [\n",
    "\"albluwi_2017_fpec\",\n",
    "\"lippmann_2012_csmp\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"Country-level cybersecurity indicators, such as those used by yarovenko_2020_sfdr, can track national progress in areas like policy development and education, reflecting posture improvements.\",\n",
    "\"cite_keys\": [\n",
    "\"yarovenko_2020_sfdr\"\n",
    "]\n",
    "}\n",
    "],\n",
    "\"follow_up_source_reading_questions\": [\n",
    "\"What specific frameworks did cassidy_2024_etac or saeed_2021_catp evaluate or find effective?\",\n",
    "\"What are the key components or levels of the metric maturity model proposed by lippmann_2012_csmp?\",\n",
    "\"What were the 12 specific country-level indicators used by yarovenko_2020_sfdr?\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"indicator_id\": \"3.4\",\n",
    "\"indicator_text\": \"Reduction in the hosting or transit of UK-relevant cybercriminal infrastructure/services within partner country jurisdictions over time.\",\n",
    "\"potential_sources\": [\n",
    "\"Threat intelligence mapping (commercial/public).\",\n",
    "\"NCSC/NCA data analysis.\",\n",
    "\"Long-term analysis from technical monitoring (Indicator 1.4).\"\n",
    "],\n",
    "\"relevant_insights\": [\n",
    "{\n",
    "\"insight_text\": \"Mapping the global geography of cybercrime using methods like expert surveys (bruce_2024_mtgg) or spatial analysis of technical data (amin_2020_tsao) allows tracking of infrastructure concentration and potential shifts away from 'hotspot' partner countries.\",\n",
    "\"cite_keys\": [\n",
    "\"bruce_2024_mtgg\",\n",
    "\"amin_2020_tsao\"\n",
    "]\n",
    "},\n",
    "{\n",
    "\"insight_text\": \"A sustained decrease in technical indicators associated with malicious hosting (e.g., number of phishing URLs, malware domains attributed to partner country IPs) provides evidence for reduced criminal activity/hosting.\",\n",
    "\"cite_keys\": [\n",
    "\"chen_2023_etgg\"\n",
    "]\n",
    "}\n",
    "],\n",
    "\"follow_up_source_reading_questions\": [\n",
    "\"What were the five major cybercrime categories used in the expert survey by bruce_2024_mtgg for the World Cybercrime Index?\",\n",
    "\"What specific spatial analysis techniques (e.g., SaTScan parameters) did amin_2020_tsao use to identify clusters of malicious URLs?\"\n",
    "]\n",
    "}\n",
    "]\n",
    "}\n",
    "]\n",
    "\n",
    "# Option 1: Use IPython's interactive JSON viewer.\n",
    "display(JSON(data))\n",
    "\n",
    "# Option 2: Flatten the JSON into a table for a consolidated view.\n",
    "rows = []\n",
    "for impact in data:\n",
    "    for indicator in impact.get(\"indicators\", []):\n",
    "        potential_sources = \"\\n\".join(indicator.get(\"potential_sources\", []))\n",
    "        insights = \"\\n\\n\".join(\n",
    "            f\"Insight: {insight.get('insight_text','')}\\nCite Keys: {', '.join(insight.get('cite_keys', []))}\"\n",
    "            for insight in indicator.get(\"relevant_insights\", [])\n",
    "        )\n",
    "        rows.append({\n",
    "            \"Impact ID\": impact.get(\"impact_id\"),\n",
    "            \"Impact Text\": impact.get(\"impact_text\"),\n",
    "            \"Indicator ID\": indicator.get(\"indicator_id\"),\n",
    "            \"Indicator Text\": indicator.get(\"indicator_text\"),\n",
    "            \"Potential Sources\": potential_sources,\n",
    "            \"Relevant Insights\": insights\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326abb81-1b32-442a-9327-1fca9bdbbfea",
   "metadata": {},
   "source": [
    "# Add follow up questions of sources to db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "115fdfa6-a607-49d4-8e29-8f2b397bf21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added source needed for question id 1: bergh_2018_voci\n",
      "Added source needed for question id 1: woods_2022_reoc\n",
      "Added question for toc_id 1, indicator I1.1: What specific survey questions or methodologies did `bergh_2018_voci` and `woods_2022_reoc` find most common or problematic for measuring cybercrime detection/victimisation?\n",
      "Added source needed for question id 2: breen_2022_alsm\n",
      "Added question for toc_id 1, indicator I1.1: How did `breen_2022_alsm` define and implement 'social-reporting techniques' in their survey to improve cybercrime measurement?\n",
      "Added source needed for question id 3: collier_2021_iiar\n",
      "Added question for toc_id 1, indicator I1.1: What specific configuration details (e.g., protocols, services mimicked) did `collier_2021_iiar` or `thomas_2017_1dou` use for their honeypots to measure DDoS attacks?\n",
      "Added source needed for question id 4: meland_2021_asms\n",
      "Added source needed for question id 4: miani_2015_apeo\n",
      "Added question for toc_id 1, indicator I1.1: What specific data points or alert characteristics from network traffic/IDPS logs did `meland_2021_asms` or `miani_2015_apeo` identify as key indicators for technical detection measurement?\n",
      "Added source needed for question id 5: hagen_2008_paua\n",
      "Added question for toc_id 1, indicator I1.1: Did `hagen_2008_paua` provide quantitative examples or benchmarks for 'weak detection mechanisms'?\n",
      "Added source needed for question id 6: miani_2015_apeo\n",
      "Added question for toc_id 1, indicator I1.1: What methods did `miani_2015_apeo` evaluate or recommend for managing false positives/alert volume in IDPS logs for better detection analysis?\n",
      "Added source needed for question id 7: kumar_2024_paoc\n",
      "Added source needed for question id 7: deepak_2023_aaft\n",
      "Added question for toc_id 1, indicator I1.1: Did `kumar_2024_paoc` or `deepak_2023_aaft` specify the data inputs, features, and performance metrics (e.g., accuracy, precision, recall) used for their AI/ML detection models?\n",
      "Added source needed for question id 8: bidgoli_2019_rnre\n",
      "Added question for toc_id 1, indicator I1.1: What specific design elements of the reporting interface did `bidgoli_2019_rnre` test and find effective for improving reporting volume or quality?\n",
      "Added source needed for question id 9: anishchuk_2024_tpoc\n",
      "Added source needed for question id 9: shevko_2024_ccsa\n",
      "Added source needed for question id 9: ugwu_2024_atet\n",
      "Added source needed for question id 9: collier_2021_iiar\n",
      "Added source needed for question id 9: hussain_2023_acao\n",
      "Added question for toc_id 1, indicator I1.1: Do the sources discussing international cooperation (`anishchuk_2024_tpoc`, `shevko_2024_ccsa`, `ugwu_2024_atet`, `collier_2021_iiar`, `hussain_2023_acao`) provide any criteria or case studies on evaluating the *timeliness* or *actionability* of information shared between international partners?\n",
      "Added source needed for question id 10: anishchuk_2024_tpoc\n",
      "Added source needed for question id 10: shevko_2024_ccsa\n",
      "Added source needed for question id 10: ugwu_2024_atet\n",
      "Added source needed for question id 10: hussain_2023_acao\n",
      "Added question for toc_id 1, indicator I1.2: Do the sources discussing international cooperation (`anishchuk_2024_tpoc`, `shevko_2024_ccsa`, `ugwu_2024_atet`, `hussain_2023_acao`) offer any qualitative or quantitative criteria for evaluating the 'quality' or 'actionability' of shared cyber threat intelligence?\n",
      "Added source needed for question id 11: chen_2023_etgg\n",
      "Added source needed for question id 11: holt_2015_cipa\n",
      "Added source needed for question id 11: kshetri_2013_rvca\n",
      "Added question for toc_id 1, indicator I1.2: Did the sources discussing measurement challenges (`armin_2015_2cec`, `chen_2023_etgg`, `holt_2015_cipa`, `kshetri_2013_rvca`) explicitly link these challenges to the quality of intelligence shared internationally?\n",
      "Added source needed for question id 12: albluwi_2017_fpec\n",
      "Added question for toc_id 1, indicator I1.2: Does `albluwi_2017_fpec` offer guidance or examples on how to apply the GQIM framework to assess the quality or utility of information products like threat intelligence reports?\n",
      "Added source needed for question id 13: na_2024_elrt\n",
      "Added question for toc_id 2, indicator I2.1: How did `na_2024_elrt` define and measure 'prosecution rate' and 'improvement in tracking' related to legal updates and blockchain forensics? What was the methodology used to arrive at the 45% and 34% figures?\n",
      "Added source needed for question id 14: moore_2007_etio\n",
      "Added question for toc_id 2, indicator I2.1: What specific metrics did `moore_2007_etio` use to measure the effectiveness of phishing website takedowns beyond removal time? Did they quantify the impact on victim loss?\n",
      "Added source needed for question id 15: collier_2021_iiar\n",
      "Added question for toc_id 2, indicator I2.1: Did `collier_2021_iiar` provide metrics or qualitative criteria used by law enforcement to assess the 'success' of disruption operations involving criminal infrastructure?\n",
      "Added source needed for question id 16: hussain_2023_acao\n",
      "Added source needed for question id 16: ugwu_2024_atet\n",
      "Added source needed for question id 16: anishchuk_2024_tpoc\n",
      "Added question for toc_id 2, indicator I2.1: Do sources discussing international frameworks (`hussain_2023_acao`, `ugwu_2024_atet`, `anishchuk_2024_tpoc`) offer any methods or case studies quantifying how these frameworks directly contributed to increased rates of successful cross-border disruptions?\n",
      "Added source needed for question id 17: agrafiotis_2018_atoc\n",
      "Added question for toc_id 2, indicator I2.2: Does `agrafiotis_2018_atoc` provide specific examples or metrics for quantifying 'individual, systemic, and inchoate damages' within their taxonomy of cyber-harms?\n",
      "Added source needed for question id 18: anderson_2012_mtco\n",
      "Added source needed for question id 18: anderson_2019_mtcc\n",
      "Added question for toc_id 2, indicator I2.2: What specific cost categories or calculation methods did `anderson_2012_mtco` or `anderson_2019_mtcc` use in their frameworks for measuring cybercrime costs that could be relevant for assessing reductions?\n",
      "Added source needed for question id 19: bergh_2018_voci\n",
      "Added source needed for question id 19: breen_2022_alsm\n",
      "Added source needed for question id 19: yarovenko_2023_diub\n",
      "Added source needed for question id 19: teunissen_2021_etco\n",
      "Added question for toc_id 2, indicator I2.2: Did the sources discussing victim surveys (`bergh_2018_voci`, `breen_2022_alsm`, `yarovenko_2023_diub`, `teunissen_2021_etco`) detail how financial loss data was collected (e.g., specific questions, recall periods) that could inform measurement of harm reduction?\n",
      "Added source needed for question id 20: srivastava_2020_docc\n",
      "Added source needed for question id 20: thomas_2020_cl\n",
      "Added question for toc_id 2, indicator I2.2: Do any of the sources on costs (`armin_2015_2cec`, `kuklytė_2017_cavo`, `srivastava_2020_docc`, `thomas_2020_cl`) propose specific models or methods for *estimating* the economic benefit or harm reduction achieved through disruption interventions?\n",
      "Added source needed for question id 21: sandoval_2010_miac\n",
      "Added question for toc_id 3, indicator I3.1: How did `sandoval_2010_miac` define and measure 'attacker cost (time-based)' in their simulation study? What parameters were included?\n",
      "Added source needed for question id 22: an_2018_adat\n",
      "Added source needed for question id 22: fajar_2020_tist\n",
      "Added question for toc_id 3, indicator I3.1: Did `an_2018_adat` or `fajar_2020_tist` provide specific methodologies or examples for analyzing the economic impact *on perpetrators* or measuring the effectiveness of targeting revenue streams?\n",
      "Added source needed for question id 23: dupont_2021_erbc\n",
      "Added source needed for question id 23: wang_2020_dcpi\n",
      "Added source needed for question id 23: meland_2021_asms\n",
      "Added question for toc_id 3, indicator I3.1: Do sources discussing criminal forums/behaviour (`dupont_2021_erbc`, `wang_2020_dcpi`, `meland_2021_asms`) offer methods for systematically tracking changes in adversary TTPs or discussions that might indicate a response to increased costs/risks?\n",
      "Added source needed for question id 24: na_2024_elrt\n",
      "Added question for toc_id 3, indicator I3.1: Did `na_2024_elrt` discuss or find evidence linking increased prosecution rates directly to changes in cybercriminal behaviour (deterrence)?\n",
      "Added question for toc_id 3, indicator I3.1: Are there established academic methodologies mentioned in any source for measuring the deterrent effect of cybersecurity interventions or law enforcement actions?\n",
      "Added source needed for question id 26: collier_2021_iiar\n",
      "Added question for toc_id 3, indicator I3.2: Did `collier_2021_iiar` or `thomas_2017_1dou` analyze long-term trends in their honeypot data that showed sustained reductions potentially linked to interventions?\n",
      "Added source needed for question id 27: bergh_2018_voci\n",
      "Added source needed for question id 27: woods_2022_reoc\n",
      "Added question for toc_id 3, indicator I3.2: Do the sources discussing victim surveys (`bergh_2018_voci`, `woods_2022_reoc`) mention specific longitudinal surveys or methodologies suitable for tracking changes in national/regional prevalence rates over time?\n",
      "Added source needed for question id 28: amin_2020_tsao\n",
      "Added question for toc_id 3, indicator I3.2: What statistical or analytical techniques did `amin_2020_tsao` use for spatial analysis that could potentially be adapted for temporal analysis of attack frequency changes?\n",
      "Added question for toc_id 3, indicator I3.2: Does any reviewed literature propose methodologies for isolating the effect of *deterrence* interventions when measuring changes in attack frequency or success rates?\n",
      "Added source needed for question id 30: collier_2021_iiar\n",
      "Added question for toc_id 4, indicator BC4.1: Did `collier_2021_iiar`'s interviews with law enforcement provide insights into how the frequency or volume of intelligence sharing is typically tracked or valued?\n",
      "Added source needed for question id 31: anishchuk_2024_tpoc\n",
      "Added source needed for question id 31: shevko_2024_ccsa\n",
      "Added source needed for question id 31: ugwu_2024_atet\n",
      "Added source needed for question id 31: hussain_2023_acao\n",
      "Added question for toc_id 4, indicator BC4.1: Do any sources discussing international cooperation (`anishchuk_2024_tpoc`, `shevko_2024_ccsa`, `ugwu_2024_atet`, `hussain_2023_acao`) describe specific mechanisms or platforms whose usage logs could quantify sharing frequency/volume between partners?\n",
      "Added source needed for question id 32: taherdoost_2024_iicd\n",
      "Added question for toc_id 4, indicator BC4.2: Does `taherdoost_2024_iicd` provide specific metrics or model components related to the time taken for *information dissemination* or inter-organizational communication in their review of detection/response time factors?\n",
      "Added question for toc_id 4, indicator BC4.2: Are there established benchmarks or standards discussed in any source for the expected timeliness of international cyber intelligence sharing?\n",
      "Added source needed for question id 34: chen_2023_etgg\n",
      "Added source needed for question id 34: holt_2015_cipa\n",
      "Added question for toc_id 5, indicator BC5.1: Do sources using official statistics (`chen_2023_etgg`, `holt_2015_cipa`, `armin_2015_2cec`) provide details on how cybercrime-related arrests/investigations are typically categorized or counted in police records?\n",
      "Added source needed for question id 35: na_2024_elrt\n",
      "Added question for toc_id 5, indicator BC5.1: How did `na_2024_elrt` measure the 'prosecution rate' used in their analysis? Did the study track the number of arrests preceding prosecutions?\n",
      "Added source needed for question id 36: brown_2015_iapc\n",
      "Added source needed for question id 36: curtis_2022_ucir\n",
      "Added source needed for question id 36: harkin_2018_tcfs\n",
      "Added question for toc_id 5, indicator BC5.1: Do the sources discussing policing challenges (`brown_2015_iapc`, `curtis_2022_ucir`, `harkin_2018_tcfs`) offer any insights into how police forces typically measure or report on the volume of cybercrime investigations or arrests?\n",
      "Added source needed for question id 37: chen_2023_etgg\n",
      "Added source needed for question id 37: holt_2015_cipa\n",
      "Added question for toc_id 5, indicator BC5.2: How are cybercrime convictions typically recorded or defined in court statistics, according to sources like `chen_2023_etgg`, `holt_2015_cipa`, or `armin_2015_2cec`?\n",
      "Added source needed for question id 38: na_2024_elrt\n",
      "Added question for toc_id 5, indicator BC5.2: What specific methodology or data source did `na_2024_elrt` use to determine the 45% increase in prosecution rates associated with modern laws?\n",
      "Added source needed for question id 39: brown_2015_iapc\n",
      "Added question for toc_id 5, indicator BC5.2: Did `brown_2015_iapc` quantify the impact of specific barriers on prosecution success rates?\n",
      "Added source needed for question id 40: moore_2007_etio\n",
      "Added source needed for question id 40: collier_2021_iiar\n",
      "Added question for toc_id 6, indicator BC6.1: Did `moore_2007_etio` or `collier_2021_iiar` provide data on the typical frequency or volume of takedown operations based on their observations or law enforcement interviews?\n",
      "Added question for toc_id 6, indicator BC6.1: Are there standard reporting formats or databases mentioned in the literature for tracking the number of infrastructure takedown operations conducted by law enforcement or CERTs?\n",
      "Added source needed for question id 42: moore_2007_etio\n",
      "Added question for toc_id 6, indicator BC6.2: What specific metrics beyond removal time did `moore_2007_etio` use or suggest for measuring phishing site takedown effectiveness?\n",
      "Added source needed for question id 43: collier_2021_iiar\n",
      "Added question for toc_id 6, indicator BC6.2: How did `collier_2021_iiar` measure or define 'growth cessation' in UK attacks observed in their time-series data? What data points were used?\n",
      "Added source needed for question id 44: meland_2021_asms\n",
      "Added question for toc_id 6, indicator BC6.2: Does `meland_2021_asms` provide specific examples of metrics derived from network traces or sinkhole data suitable for measuring the impact of takedowns?\n",
      "Added question for toc_id 6, indicator BC6.2: Does any source propose a standardized framework or set of metrics for evaluating the overall effectiveness of criminal infrastructure takedown operations?\n",
      "Added source needed for question id 46: ng_2023_wwdi\n",
      "Added source needed for question id 46: voce_2023_cia\n",
      "Added source needed for question id 46: vakhitova_2020_tson\n",
      "Added question for toc_id 7, indicator BC7.1: What specific protective practices or tool adoptions were measured by `ng_2023_wwdi`, `voce_2023_cia2`, or `vakhitova_2020_tson` in their surveys?\n",
      "Added source needed for question id 47: yarovenko_2023_diub\n",
      "Added question for toc_id 7, indicator BC7.1: What survey questions or methodologies did `yarovenko_2023_diub` use to measure 'responsible behavior' or adoption of specific security practices?\n",
      "Added source needed for question id 48: sawyer_2018_htht\n",
      "Added question for toc_id 7, indicator BC7.1: How did `sawyer_2018_htht` set up their simulation to measure user accuracy and response time in detecting attack emails?\n",
      "Added source needed for question id 49: bergh_2018_voci\n",
      "Added source needed for question id 49: woods_2022_reoc\n",
      "Added question for toc_id 7, indicator BC7.2: What recommendations did `bergh_2018_voci` or `woods_2022_reoc` make regarding survey design (e.g., question wording, recall period) to improve the reliability of victimization rate estimates?\n",
      "Added source needed for question id 50: bergh_2018_voci\n",
      "Added source needed for question id 50: breen_2022_alsm\n",
      "Added source needed for question id 50: voce_2023_cia\n",
      "Added source needed for question id 50: woods_2022_reoc\n",
      "Added question for toc_id 7, indicator BC7.2: Did any of the victim survey studies (`bergh_2018_voci`, `breen_2022_alsm`, `voce_2023_cia2`, `woods_2022_reoc`) use a longitudinal design to track changes in individual victimization over time?\n",
      "Added source needed for question id 51: dupont_2019_eteo\n",
      "Added question for toc_id 8, indicator BC8.1: Does `dupont_2019_eteo` provide a specific template or key data points recommended for systematically tracking the enactment of cybercrime-related policies?\n",
      "Added source needed for question id 52: na_2024_elrt\n",
      "Added source needed for question id 52: adomako_2018_acpe\n",
      "Added source needed for question id 52: ugwu_2024_atet\n",
      "Added question for toc_id 8, indicator BC8.1: How did `na_2024_elrt`, `adomako_2018_acpe`, or `ugwu_2024_atet` categorize or define 'modern', 'specific', 'partial', or 'meaningful' cybercrime laws in their analyses of national legislation?\n",
      "Added question for toc_id 8, indicator BC8.1: Are there specific databases or resources mentioned in the literature for tracking the global status of legislation related to cyber intrusion capabilities?\n",
      "Added source needed for question id 54: chen_2023_etgg\n",
      "Added source needed for question id 54: holt_2015_cipa\n",
      "Added question for toc_id 8, indicator BC8.2: How are enforcement actions related to the *regulation of intrusion capabilities* specifically tracked or reported in official statistics, according to sources discussing such data (`chen_2023_etgg`, `holt_2015_cipa`, `armin_2015_2cec`)?\n",
      "Added source needed for question id 55: na_2024_elrt\n",
      "Added question for toc_id 8, indicator BC8.2: Did `na_2024_elrt` provide examples of specific types of enforcement actions taken under 'modern' cybercrime laws relevant to intrusion capabilities?\n",
      "Added question for toc_id 8, indicator BC8.2: Do any sources discuss methods for tracking administrative or non-criminal enforcement actions (e.g., sanctions, license revocations) related to intrusion tool regulation?\n",
      "Added source needed for question id 57: brown_2015_iapc\n",
      "Added question for toc_id 9, indicator BC9.1: Does `brown_2015_iapc` or other sources discuss the typical processes or evidentiary thresholds governments use before making public attributions, which might inform how to assess the significance of an attribution act?\n",
      "Added question for toc_id 9, indicator BC9.1: Are there established databases or tracking mechanisms mentioned in the literature that specifically catalogue instances of public cyber incident attribution by governments?\n",
      "Added source needed for question id 59: veresha_2018_pmac\n",
      "Added source needed for question id 59: yarovenko_2020_sfdr\n",
      "Added source needed for question id 59: li_2024_mgmo\n",
      "Added question for toc_id 9, indicator BC9.2: Do sources discussing preventive measures (`veresha_2018_pmac`, `yarovenko_2020_sfdr`, `li_2024_mgmo`) offer ways to distinguish or measure specifically *pre-emptive* actions against anticipated threats?\n",
      "Added source needed for question id 60: yarovenko_2020_sfdr\n",
      "Added source needed for question id 60: enoch_2020_cmfn\n",
      "Added question for toc_id 9, indicator BC9.2: Are there frameworks or indicators in `yarovenko_2020_sfdr` or `enoch_2020_cmfn` suitable for measuring national capabilities for pre-emptive cyber defense actions?\n",
      "Added source needed for question id 61: dupont_2019_eteo\n",
      "Added question for toc_id 9, indicator BC9.2: Does `dupont_2019_eteo`'s proposed policy monitoring include tracking specific pre-emptive policy measures (like sanctions or diplomatic actions) related to cyber threats?\n",
      "Added question for toc_id 10, indicator CD10.1: Are there established methods or criteria discussed in the literature for evaluating the quality, depth, or impact of cyber threat intelligence analysis or research reports?\n",
      "Added source needed for question id 63: meland_2021_asms\n",
      "Added source needed for question id 63: chen_2023_etgg\n",
      "Added source needed for question id 63: dupont_2021_erbc\n",
      "Added question for toc_id 10, indicator CD10.1: Do sources discussing data sources for threat analysis (`meland_2021_asms`, `chen_2023_etgg`, `dupont_2021_erbc`) offer insights into how the quality of analysis is linked to the data used?\n",
      "Added source needed for question id 64: anishchuk_2024_tpoc\n",
      "Added source needed for question id 64: shevko_2024_ccsa\n",
      "Added source needed for question id 64: ugwu_2024_atet\n",
      "Added source needed for question id 64: hussain_2023_acao\n",
      "Added question for toc_id 10, indicator CD10.2: Do the sources emphasizing international cooperation (`anishchuk_2024_tpoc`, `shevko_2024_ccsa`, `ugwu_2024_atet`, `hussain_2023_acao`) provide examples or case studies detailing the types of mechanisms commonly used for sharing analytical understanding between governments or agencies?\n",
      "Added source needed for question id 65: chen_2023_etgg\n",
      "Added source needed for question id 65: holt_2015_cipa\n",
      "Added question for toc_id 11, indicator BC11.1: How do official statistics sources (`chen_2023_etgg`, `holt_2015_cipa`, `armin_2015_2cec`) typically count or categorize 'detected and analyzed' cybercrime cases?\n",
      "Added source needed for question id 66: amin_2020_tsao\n",
      "Added source needed for question id 66: kumar_2024_paoc\n",
      "Added question for toc_id 11, indicator BC11.1: Did `amin_2020_tsao`'s spatial analysis or `kumar_2024_paoc`'s pattern analysis provide metrics that could be used to assess the volume or significance of detected activity?\n",
      "Added source needed for question id 67: hagen_2008_paua\n",
      "Added source needed for question id 67: miani_2015_apeo\n",
      "Added question for toc_id 11, indicator BC11.1: Do sources discussing detection challenges (`hagen_2008_paua`, `miani_2015_apeo`) offer methods for quantifying the *quality* of detection (e.g., beyond simple counts)?\n",
      "Added question for toc_id 11, indicator BC11.1: Are there standard frameworks or criteria mentioned for assessing the quality of cybercrime analysis conducted by law enforcement partners?\n",
      "Added source needed for question id 69: taherdoost_2024_iicd\n",
      "Added question for toc_id 12, indicator CD12.1: Does `taherdoost_2024_iicd` provide specific metrics or benchmarks for internal processing times related to incident response or information preparation?\n",
      "Added source needed for question id 70: curtis_2022_ucir\n",
      "Added source needed for question id 70: harkin_2018_tcfs\n",
      "Added source needed for question id 70: dlamini_2019_upoc\n",
      "Added question for toc_id 12, indicator CD12.1: Do sources discussing policing challenges (`curtis_2022_ucir`, `harkin_2018_tcfs`, `dlamini_2019_upoc`) offer insights into how police measure or benchmark their own response/processing times for cybercrime cases?\n",
      "Added source needed for question id 71: brown_2015_iapc\n",
      "Added question for toc_id 12, indicator CD12.2: Did `brown_2015_iapc` offer any specific criteria or examples related to the necessary quality or completeness of information required for successful cybercrime prosecution?\n",
      "Added source needed for question id 72: kshetri_2013_rvca\n",
      "Added question for toc_id 12, indicator CD12.2: Do sources discussing measurement challenges (`armin_2015_2cec`, `kshetri_2013_rvca`) link these directly to the quality of evidence packages prepared by law enforcement?\n",
      "Added source needed for question id 73: albluwi_2017_fpec\n",
      "Added question for toc_id 12, indicator CD12.2: Does `albluwi_2017_fpec` provide guidance on using GQIM to define metrics for the quality of informational outputs or reports?\n",
      "Added source needed for question id 74: anishchuk_2024_tpoc\n",
      "Added source needed for question id 74: shevko_2024_ccsa\n",
      "Added source needed for question id 74: ugwu_2024_atet\n",
      "Added source needed for question id 74: hussain_2023_acao\n",
      "Added source needed for question id 74: collier_2021_iiar\n",
      "Added question for toc_id 13, indicator CD13.1: Do sources discussing international cooperation (`anishchuk_2024_tpoc`, `shevko_2024_ccsa`, `ugwu_2024_atet`, `hussain_2023_acao`, `collier_2021_iiar`) mention specific platforms or processes whose effectiveness has been evaluated, and if so, how?\n",
      "Added question for toc_id 13, indicator CD13.1: Are there standard methods or metrics proposed in the literature for assessing the functionality or user satisfaction with international information sharing platforms in the law enforcement context?\n",
      "Added question for toc_id 13, indicator CD13.1: Are usage statistics (e.g., number of users, frequency of access, volume shared) commonly used metrics for evaluating such platforms, based on the literature?\n",
      "Added source needed for question id 77: dupont_2019_eteo\n",
      "Added question for toc_id 14, indicator CD14.1: Does `dupont_2019_eteo`'s policy monitoring framework include indicators related to the level of political priority or resource allocation associated with cybercrime policies?\n",
      "Added source needed for question id 78: harkin_2018_tcfs\n",
      "Added source needed for question id 78: dlamini_2019_upoc\n",
      "Added question for toc_id 14, indicator CD14.1: Do `harkin_2018_tcfs` or `dlamini_2019_upoc` provide quantitative data or typical metrics used to track resource allocation (funding, staffing) for police cybercrime units?\n",
      "Added source needed for question id 79: adomako_2018_acpe\n",
      "Added question for toc_id 14, indicator CD14.2: How did `adomako_2018_acpe` measure 'Accession to the Budapest convention' as a KPI? Did they consider other forms of participation in international initiatives?\n",
      "Added question for toc_id 14, indicator CD14.2: Do any sources propose metrics for assessing the *quality* or *influence* of a country's participation in international cyber cooperation, beyond just being a member?\n",
      "Added source needed for question id 81: drew_2018_ovra\n",
      "Added source needed for question id 81: yarovenko_2023_diub\n",
      "Added question for toc_id 15, indicator CD15.1: Did `drew_2018_ovra` or `yarovenko_2023_diub` use specific survey questions or methods to assess user *knowledge* (distinct from behaviour or risk perception)?\n",
      "Added source needed for question id 82: veresha_2018_pmac\n",
      "Added source needed for question id 82: yarovenko_2020_sfdr\n",
      "Added question for toc_id 15, indicator CD15.1: Do sources discussing education (`veresha_2018_pmac`, `yarovenko_2020_sfdr`) mention how the effectiveness of such education (knowledge gain) is typically measured?\n",
      "Added question for toc_id 15, indicator CD15.2: Does any reviewed source discuss methodologies for assessing the accessibility or usability of security tools specifically for high-risk or non-expert user groups?\n",
      "Added source needed for question id 84: veresha_2018_pmac\n",
      "Added question for toc_id 16, indicator CD16.1: Does `veresha_2018_pmac` offer any methods for measuring changes in public or political 'attitudes' resulting from awareness campaigns or propaganda?\n",
      "Added question for toc_id 16, indicator CD16.1: Are there standard methodologies discussed in the literature for measuring the impact of advocacy campaigns on policy agendas or political discourse in the cybersecurity domain?\n",
      "Finished extracting and saving follow-up questions and associated source cite_keys.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from models.db_models import FollowUpQuestion, SourcesNeededForFollowUps, engine\n",
    "from config import NotebookConfig\n",
    "\n",
    "# Create a new SQLAlchemy session.\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "# Define a regex pattern to extract cite_keys (pattern: letters_digits_letters)\n",
    "# This pattern matches one or more lowercase letters, an underscore, exactly 4 digits, another underscore,\n",
    "# and one or more lowercase letters.\n",
    "pattern = r'([a-z]+_[0-9]{4}_[a-z]+)'\n",
    "\n",
    "# Define the path to the proposed_indicators.txt file.\n",
    "json_file_path = NotebookConfig.INPUT_DIR / \"proposed_indicators.txt\"\n",
    "\n",
    "# Load the JSON content.\n",
    "with open(json_file_path, 'r') as file:\n",
    "    toc_data = json.load(file)\n",
    "\n",
    "# Loop through each ToC node and its indicators.\n",
    "for toc in toc_data:\n",
    "    toc_id = toc.get(\"toc_id\")\n",
    "    for indicator in toc.get(\"indicators\", []):\n",
    "        indicator_id = indicator.get(\"indicator_id\")\n",
    "        questions = indicator.get(\"follow_up_source_reading_questions\", [])\n",
    "        for question_text in questions:\n",
    "            # Create a new FollowUpQuestion record.\n",
    "            new_question = FollowUpQuestion(\n",
    "                toc_id=toc_id,\n",
    "                indicator_id=indicator_id,\n",
    "                question_text=question_text\n",
    "            )\n",
    "            session.add(new_question)\n",
    "            # Flush the session to assign an ID to new_question.\n",
    "            session.flush()\n",
    "            \n",
    "            # Extract cite_keys from the question text.\n",
    "            matches = re.findall(pattern, question_text)\n",
    "            for cite_key in matches:\n",
    "                new_source_needed = SourcesNeededForFollowUps(\n",
    "                    question_id=new_question.id,\n",
    "                    cite_key=cite_key\n",
    "                )\n",
    "                session.add(new_source_needed)\n",
    "                print(f\"Added source needed for question id {new_question.id}: {cite_key}\")\n",
    "            \n",
    "            print(f\"Added question for toc_id {toc_id}, indicator {indicator_id}: {question_text}\")\n",
    "\n",
    "# Commit all changes.\n",
    "session.commit()\n",
    "print(\"Finished extracting and saving follow-up questions and associated source cite_keys.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bc1a69c-d9fd-4c71-bac8-a8bb9278a6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View 'vw_unique_cite_keys_for_follow_ups' with link and open_access_link has been created (if it did not already exist).\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from config import NotebookConfig\n",
    "\n",
    "# Create the database engine.\n",
    "engine = create_engine(f\"sqlite:///{NotebookConfig.DB_FILE}\")\n",
    "\n",
    "# SQL statement to create a view with unique cite_keys, along with link and open_access_link.\n",
    "create_view_sql = text(\"\"\"\n",
    "    CREATE VIEW IF NOT EXISTS vw_unique_cite_keys_for_follow_ups AS\n",
    "    SELECT DISTINCT s.cite_key, s.link, s.open_access_link\n",
    "    FROM sources_needed_for_follow_ups snf\n",
    "    JOIN source s ON snf.cite_key = s.cite_key;\n",
    "\"\"\")\n",
    "\n",
    "# Execute the SQL statement.\n",
    "with engine.begin() as connection:\n",
    "    connection.execute(create_view_sql)\n",
    "\n",
    "print(\"View 'vw_unique_cite_keys_for_follow_ups' with link and open_access_link has been created (if it did not already exist).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d606b0-7dd4-4609-bfeb-1a394b1b7f56",
   "metadata": {},
   "source": [
    "# Helper cell: print the indicators from the potential_indicators.txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed675709-91d8-46a4-970a-c639dc067451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table saved to output_docs/proposed_indicator_table_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from config import NotebookConfig\n",
    "\n",
    "# Define the path to the JSON file.\n",
    "json_file_path = NotebookConfig.INPUT_DIR / \"proposed_indicators_and_sources.txt\"\n",
    "\n",
    "# Load the JSON content.\n",
    "with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Prepare a list to hold rows for our table.\n",
    "rows = []\n",
    "\n",
    "# Iterate over each topic in the JSON data.\n",
    "for toc in data:\n",
    "    topic_id = toc.get(\"toc_id\")\n",
    "    topic_text = toc.get(\"toc_text\")\n",
    "    topic_level = toc.get(\"toc_level\")\n",
    "    \n",
    "    # Process each indicator in the topic.\n",
    "    for indicator in toc.get(\"indicators\", []):\n",
    "        indicator_id = indicator.get(\"indicator_id\")\n",
    "        indicator_text = indicator.get(\"indicator_text\")\n",
    "        potential_sources = indicator.get(\"potential_sources\", [])\n",
    "        \n",
    "        # Ensure potential_sources is a list.\n",
    "        if not isinstance(potential_sources, list):\n",
    "            potential_sources = [potential_sources]\n",
    "        # If there are no sources, use an empty string.\n",
    "        if not potential_sources:\n",
    "            potential_sources = ['']\n",
    "        \n",
    "        # For each potential source, create a row.\n",
    "        # The first source gets the full topic/indicator details; subsequent ones get blank details.\n",
    "        for i, source in enumerate(potential_sources):\n",
    "            if i == 0:\n",
    "                rows.append({\n",
    "                    \"topic_id\": topic_id,\n",
    "                    \"topic_text\": topic_text,\n",
    "                    \"topic_level\": topic_level,\n",
    "                    \"indicator_id\": indicator_id,\n",
    "                    \"indicator_text\": indicator_text,\n",
    "                    \"potential_sources\": source\n",
    "                })\n",
    "            else:\n",
    "                rows.append({\n",
    "                    \"topic_id\": \"\",\n",
    "                    \"topic_text\": \"\",\n",
    "                    \"topic_level\": \"\",\n",
    "                    \"indicator_id\": \"\",\n",
    "                    \"indicator_text\": \"\",\n",
    "                    \"potential_sources\": source\n",
    "                })\n",
    "\n",
    "# Create a DataFrame from the rows.\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Reorder columns if desired.\n",
    "df = df[[\"topic_id\", \"topic_text\", \"topic_level\", \"indicator_id\", \"indicator_text\", \"potential_sources\"]]\n",
    "\n",
    "# Save the DataFrame to a CSV file in the output directory with UTF-8 encoding.\n",
    "output_path = NotebookConfig.OUTPUT_DIR / \"proposed_indicator_table_clean.csv\"\n",
    "df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "print(f\"Table saved to {output_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922e322f-c544-4028-b784-e608fba24dce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
